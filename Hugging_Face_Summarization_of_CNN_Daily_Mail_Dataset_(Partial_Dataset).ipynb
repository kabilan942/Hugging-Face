{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUQFdEAp8ZYuLhhkXJizEf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ca6339245ef640ada8becf290a12b499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_353a40b8e41d4eeca6b62a5abebccd91",
              "IPY_MODEL_aaf27f00c6f34500ae04d816f7118ccf",
              "IPY_MODEL_01b740a6947c4e25bc06bb5ff78e633c"
            ],
            "layout": "IPY_MODEL_3924f2cd6d294295b458bcd8f77d09c5"
          }
        },
        "353a40b8e41d4eeca6b62a5abebccd91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4aeaa076b5a4ea9be978e9fc50e0cdd",
            "placeholder": "​",
            "style": "IPY_MODEL_1db586a4061a45d2a07af535c833e5ca",
            "value": "  0%"
          }
        },
        "aaf27f00c6f34500ae04d816f7118ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43cf8426f7b04a43ba0f4297e61d3cac",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1bb67f464cc49a1a0458708b2a30900",
            "value": 0
          }
        },
        "01b740a6947c4e25bc06bb5ff78e633c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5008879e3b534d9ba1beafafd1a70350",
            "placeholder": "​",
            "style": "IPY_MODEL_02dcfe2f3dc849d0a5e1af845c952c75",
            "value": " 0/1 [00:00&lt;?, ?ba/s]"
          }
        },
        "3924f2cd6d294295b458bcd8f77d09c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4aeaa076b5a4ea9be978e9fc50e0cdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1db586a4061a45d2a07af535c833e5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43cf8426f7b04a43ba0f4297e61d3cac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1bb67f464cc49a1a0458708b2a30900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5008879e3b534d9ba1beafafd1a70350": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02dcfe2f3dc849d0a5e1af845c952c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52bff9bfdae042baa520669886a8dcfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_216f1a75561c4d889dbf26bc0c2cbc0b",
              "IPY_MODEL_01fc60bf3af446f4b243fc9c88bb1e6d",
              "IPY_MODEL_6ca1ecbcb5bb461b91b3a67c52e54aa3"
            ],
            "layout": "IPY_MODEL_0464505ca94b493eaf00888b6dace609"
          }
        },
        "216f1a75561c4d889dbf26bc0c2cbc0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_046112dbed294a8bbcf336232762b883",
            "placeholder": "​",
            "style": "IPY_MODEL_a0f762d30dbd44c39c026a3277c59601",
            "value": "  0%"
          }
        },
        "01fc60bf3af446f4b243fc9c88bb1e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc91bd4d60084e77997b9b9a3e7f674a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd6fe33594fc447c89baa1f02a0a2a90",
            "value": 0
          }
        },
        "6ca1ecbcb5bb461b91b3a67c52e54aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cc053524ebc4ec49acc7489e1b0f279",
            "placeholder": "​",
            "style": "IPY_MODEL_a70f1f57c51a4d8d8cb61b3fca683055",
            "value": " 0/1 [00:00&lt;?, ?ba/s]"
          }
        },
        "0464505ca94b493eaf00888b6dace609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "046112dbed294a8bbcf336232762b883": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0f762d30dbd44c39c026a3277c59601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc91bd4d60084e77997b9b9a3e7f674a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd6fe33594fc447c89baa1f02a0a2a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cc053524ebc4ec49acc7489e1b0f279": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a70f1f57c51a4d8d8cb61b3fca683055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c904c900a6eb4dd98a1f83d031585662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59554b0c0b3744fe93fdaf7246ee0f26",
              "IPY_MODEL_94d999b92cad464fbe845448f89b9159",
              "IPY_MODEL_0cf33b6475fd483398a60f9219c288a8"
            ],
            "layout": "IPY_MODEL_94c483c7c3b74b12bf5acceac11b7489"
          }
        },
        "59554b0c0b3744fe93fdaf7246ee0f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_755073ce3796416194122ee88181a3ea",
            "placeholder": "​",
            "style": "IPY_MODEL_8d87604dfbef4ccd9fbb93222395dbbf",
            "value": "  0%"
          }
        },
        "94d999b92cad464fbe845448f89b9159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23bf8a423cdf4c688781ac971ed5f65a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff7c294de5ba4efc8f07ecea6d202f4c",
            "value": 0
          }
        },
        "0cf33b6475fd483398a60f9219c288a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cef939c4de3484682decf6383921d51",
            "placeholder": "​",
            "style": "IPY_MODEL_b965d141b31d4d629a9c576eb3ffac86",
            "value": " 0/1 [00:00&lt;?, ?ba/s]"
          }
        },
        "94c483c7c3b74b12bf5acceac11b7489": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "755073ce3796416194122ee88181a3ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d87604dfbef4ccd9fbb93222395dbbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23bf8a423cdf4c688781ac971ed5f65a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff7c294de5ba4efc8f07ecea6d202f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cef939c4de3484682decf6383921d51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b965d141b31d4d629a9c576eb3ffac86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a555c7e8efe543749a71e84b41ebad1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f2a114990584102b9bb31d8be3e9d1b",
              "IPY_MODEL_80438cbc00974dedb5db66e0972a44c7",
              "IPY_MODEL_499031bd997341cda9f83d8a72a46276"
            ],
            "layout": "IPY_MODEL_390f720f77334615bb2656ac079a1f35"
          }
        },
        "8f2a114990584102b9bb31d8be3e9d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59e6a91c81dd4978bf4a414ac973600e",
            "placeholder": "​",
            "style": "IPY_MODEL_cc8e41446f1d48ef89d9d639b2d13367",
            "value": "Downloading builder script: 100%"
          }
        },
        "80438cbc00974dedb5db66e0972a44c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2967ea52f2a7489d8dd2007970ab6bf7",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0617419afe74eba908b67d25dd77ac5",
            "value": 6270
          }
        },
        "499031bd997341cda9f83d8a72a46276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfdaee5d094748248b540412cca909cb",
            "placeholder": "​",
            "style": "IPY_MODEL_ef69b05a6b984e1bac3db072838697cf",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 146kB/s]"
          }
        },
        "390f720f77334615bb2656ac079a1f35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59e6a91c81dd4978bf4a414ac973600e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc8e41446f1d48ef89d9d639b2d13367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2967ea52f2a7489d8dd2007970ab6bf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0617419afe74eba908b67d25dd77ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfdaee5d094748248b540412cca909cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef69b05a6b984e1bac3db072838697cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kabilan942/Hugging-Face/blob/main/Hugging_Face_Summarization_of_CNN_Daily_Mail_Dataset_(Partial_Dataset).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hugging Face - Summarization of CNN Daily Mail Dataset (Partial Dataset)**"
      ],
      "metadata": {
        "id": "7-iEWDY_N5-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Installing transformers and Exploring Dataset**"
      ],
      "metadata": {
        "id": "eHgoJUrUN5W8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFwHYQGsOSop",
        "outputId": "3c23d8c6-edf6-497e-99e9-9b9b33166d57"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Hia48BkOZou",
        "outputId": "1b047fa0-6b00-40f0-f4bb-97ea85296b8c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.6.1-py3-none-any.whl (441 kB)\n",
            "\u001b[K     |████████████████████████████████| 441 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting dill<0.3.6\n",
            "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[K     |████████████████████████████████| 95 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.10.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 41.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 55.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 61.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 57.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, dill, xxhash, responses, multiprocess, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "Successfully installed datasets-2.6.1 dill-0.3.5.1 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git config --global user.email \"kabilanp942@gmail.com\"\n",
        "# !git config --global user.name \"Kabilan.P\""
      ],
      "metadata": {
        "id": "u7r_XSRNOaL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "\n",
        "# notebook_login()"
      ],
      "metadata": {
        "id": "rFAdaU44OSq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_ds = load_dataset('cnn_dailymail','3.0.0', split='train[:300]')\n",
        "valid_ds = load_dataset('cnn_dailymail','3.0.0', split='validation[:150]')\n",
        "test_ds = load_dataset('cnn_dailymail','3.0.0', split='test[:10]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zxE3HPNOeRy",
        "outputId": "e26830d6-7c78-48eb-99cd-7aea73c47427"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n",
            "WARNING:datasets.builder:Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n",
            "WARNING:datasets.builder:Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxwvPU3JP2KB",
        "outputId": "2cfeed11-3f93-403e-b39b-253ba77a137b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['article', 'highlights', 'id'],\n",
              "    num_rows: 300\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining the Train, Validation and Test datasets into a single Dataset.Dict"
      ],
      "metadata": {
        "id": "Dfy3YONtParn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "\n",
        "datasets = datasets.DatasetDict({\"train\":train_ds, \"validation\":valid_ds, \"test\":test_ds})"
      ],
      "metadata": {
        "id": "7LZ9lTooPhKF"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndZ3_eSXOeT6",
        "outputId": "a793bb10-4dea-4ea6-ea04-4f2018cd98b4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 300\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 150\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 10\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w0eJPusOeY9",
        "outputId": "689ddd4f-1a53-43a1-8dc7-30cb73ab6ac4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.dataset_dict.DatasetDict"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets['train'][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oObjUGoAQ-_a",
        "outputId": "6cbbf656-27fc-4c3f-e5d4-9fbc05b8989d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'article': 'WASHINGTON (CNN) -- Doctors removed five small polyps from President Bush\\'s colon on Saturday, and \"none appeared worrisome,\" a White House spokesman said. The polyps were removed and sent to the National Naval Medical Center in Bethesda, Maryland, for routine microscopic examination, spokesman Scott Stanzel said. Results are expected in two to three days. All were small, less than a centimeter [half an inch] in diameter, he said. Bush is in good humor, Stanzel said, and will resume his activities at Camp David. During the procedure Vice President Dick Cheney assumed presidential power. Bush reclaimed presidential power at 9:21 a.m. after about two hours. Doctors used \"monitored anesthesia care,\" Stanzel said, so the president was asleep, but not as deeply unconscious as with a true general anesthetic. He spoke to first lady Laura Bush -- who is in Midland, Texas, celebrating her mother\\'s birthday -- before and after the procedure, Stanzel said. Afterward, the president played with his Scottish terriers, Barney and Miss Beazley, Stanzel said. He planned to have lunch at Camp David and have briefings with National Security Adviser Stephen Hadley and White House Chief of Staff Josh Bolten, and planned to take a bicycle ride Saturday afternoon. Cheney, meanwhile, spent the morning at his home on Maryland\\'s eastern shore, reading and playing with his dogs, Stanzel said. Nothing occurred that required him to take official action as president before Bush reclaimed presidential power. The procedure was supervised by Dr. Richard Tubb, Bush\\'s physician, and conducted by a multidisciplinary team from the National Naval Medical Center in Bethesda, Maryland, the White House said. Bush\\'s last colonoscopy was in June 2002, and no abnormalities were found, White House spokesman Tony Snow said. The president\\'s doctor had recommended a repeat procedure in about five years. A colonoscopy is the most sensitive test for colon cancer, rectal cancer and polyps, small clumps of cells that can become cancerous, according to the Mayo Clinic. Small polyps may be removed during the procedure. Snow said on Friday that Bush had polyps removed during colonoscopies before becoming president. Snow himself is undergoing chemotherapy for cancer that began in his colon and spread to his liver.  Watch Snow talk about Bush\\'s procedure and his own colon cancer » . \"The president wants to encourage everybody to use surveillance,\" Snow said. The American Cancer Society recommends that people without high risk factors or symptoms begin getting screened for signs of colorectal cancer at age 50. E-mail to a friend .',\n",
              " 'highlights': 'Five small polyps found during procedure; \"none worrisome,\" spokesman says .\\nPresident reclaims powers transferred to vice president .\\nBush undergoes routine colonoscopy at Camp David .',\n",
              " 'id': '24521a2abb2e1f5e34e6824e0f9e56904a2b0e88'}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since each article is accompanied by a short highlight, we can use the highlights as the target summaries for our model to learn from.\n",
        "\n",
        "Therefore, the review information we are interested in is contained in the **'articles'** and 'highlights' columns."
      ],
      "metadata": {
        "id": "0KE4TI9ARBEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_samples(dataset, num_samples=3, seed=42):\n",
        "  sample = dataset[\"train\"].shuffle(seed=seed).select(range(num_samples))   \n",
        "  # dataset['train'] used as Dataset for shuffle() and dataset[\"train\"].shuffle(seed=seed) is used as Dataset for select()\n",
        "  for example in sample:\n",
        "    print()\n",
        "    print(\">> Article: {}\".format(example['article']))\n",
        "    print(\">> Highlights: {}\".format(example['highlights']))\n",
        "\n",
        "show_samples(datasets)   # num_samples = 3 and seed = 42"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "847QLVdtRBHA",
        "outputId": "cd111769-524d-416a-e80d-37cdef3c0828"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">> Article: ATLANTA, Georgia (CNN) -- I was 14 at the time. Lebanon's civil war was in full flood. One afternoon the shells began raining down on our neighborhood in Beirut. A Lebanese woman and her son run through west Beirut in 1989 during fighting between rival forces. We ran from school screaming. Forget the book bags, classmates, homework. Just run. Out of breath, my knees giving way, it seemed to take forever to reach our local shelter -- a dark humid room at the back of our apartment block. The memory of that terrifying afternoon receded -- until recently. After more than a decade of relative peace and reconstruction, the bombings and assassinations have returned to Beirut. Every time I hear of a new explosion, I think of a frightened child sitting in darkness. In 1988, I watched the last throes of Lebanon's civil war firsthand -- and like millions of Lebanese, sad, frustrated and often fearful.  See a timeline of Lebanon's recent history » . Now I watch from another continent, but I find those same emotions resurfacing. The conspiracies, the car bombs, the threatening rhetoric and political deadlock are eerily familiar. The actors are like shadows from a long gone past. They are grayer perhaps --  those who have avoided assassination. But the cast in Lebanon's tragedy has changed little in two decades. Then, as now, a presidential election is the setting, and the struggle where religion and clan play the main roles threatens to set Lebanon back 20 years.  See bios of Lebanon's major players » . In 1988, the president's term was coming to an end and the warring factions were unable to agree on a new candidate. Militias prevented parliament members from reaching the assembly building. Compromise was nowhere in sight. The West had abandoned Lebanon to the manipulation of its neighbors. Syria had its choice for president; Israel had its own allies -- a foil for growing Muslim radicalism. The country was awash with weapons. In his last act as president, Amin Gemayel named fellow Christian and Army Chief Michel Aoun as prime minister. At a stroke, he shattered the convention that a Muslim hold that position. Muslims refused to serve in the Cabinet and the country ended up with two governments. Aoun famously declared: \"I am prime minister and six ministers in one.\" Aoun's \"War of Liberation\" against Syria turned into defeat. Then, he turned on fellow Christians of the Lebanese Forces in the \"War of Elimination.\" When that failed, the Syrians drove Aoun to take refuge at the French Embassy. In August 1990, I came to CNN as a World Report panelist. I tried to explain Lebanon's chaos, the bewildering array of factions and the horrors of civil war for ordinary civilians. I had seen people killed in front of me; children orphaned in seconds, parents burying their infants in oversize white coffins. So when I was offered the opportunity to stay at CNN, I gratefully accepted the chance to escape the anarchy. But almost as I left, the civil war was being laid to rest. The various factions had fought each other to a standstill; Arab governments, supported by the West, helped negotiate a new constitutional framework overseen by Syrian influence. Peace came to Lebanon, but it would be five years before I returned. In 1995, I went back and was stunned. I kept looking around for checkpoints manned by militants. I couldn't believe that I could go anywhere without being harassed or kidnapped by one faction or another. No longer did identity -- Christian, Muslim or Druze -- define where Lebanese could go. People mixed freely in chic coffee shops and smoked the hubble-bubble, laughing at the same jokes. It was as if Lebanon's divisions had been wiped away by some magic eraser. Downtown Beirut, once rocked by explosions and pitted with bullet holes, was rocking to Lebanese pop music. The dusty sandbags had given way to boutiques carrying the latest European fashions and deluxe hotels. Lovers had returned to Beirut's Corniche, overlooking the Mediterranean, for romantic strolls at sunset. But the agreement that ended the civil war was more a truce than a real settlement -- and was overseen by a \"pax Syriana.\" As anti-Syrian sentiment grew, so did political tensions. On Valentine's Day 2005, the Corniche was once again rocked by an explosion.  Former Prime Minister Rafik Hariri was killed. The symbolism left me speechless. On the day of love, Lebanon was thrown back into its most hateful history. It had been widely expected that Hariri would run for office again and demand the withdrawal of Syrian troops. Suspicion fell on Damascus, which vehemently denied involvement. On March 14, Martyrs' Square became a human sea of demonstrators: Muslims, Druze and Christians alike, demanding the \"truth.\" But Hariri's death also exposed the fault lines that had broken Lebanon a generation previously. Even after it withdrew its troops, Syria still had allies in Lebanon. One was Hezbollah, accused of the suicide attacks that had killed scores of U.S. Marines in Beirut more than 20 years previously. Another was Gen. Michel Aoun; now back from exile, the same Michel Aoun who had defied Syria in 1989, but who now made common cause with Hezbollah against his fellow Christians. Earlier this year I visited Martyrs' Square. The spirit of the Cedar Revolution had evaporated. The place looked like a morgue. Anti-government Hezbollah squatters had brought life there to a standstill. As I passed through, business owners stood silent in the sun and shook their heads at me in despair. I wondered if they sensed my disappointment, my pain at watching Beirut bleed again. Lebanon's political actors now find themselves re-enacting scenes from the final act of the civil war 19 years ago. Once again, the term of the president is approaching its end; there is no agreement on his successor. Suspicion and fear are the political currency of the day. And the questions haunts me: Will the country's brief renaissance that so amazed me in 1995 be snuffed out by the old curse of sectarian rivalries? E-mail to a friend . CNN's Joe Sterling, David Ariosto, Saad Abedine and Tracy Doueiry contributed to this report.\n",
            ">> Highlights: CNN's Octavia Nasr: Will Lebanon's brief renaissance be snuffed out?\n",
            "Nasr says Lebanon's key power players haven't changed since 1980s .\n",
            "Nasr: Current struggle threatens to set Lebanon back 20 years .\n",
            "\n",
            ">> Article: • The twins get a check-up (2/26/08) • VIDEO: Nancy Grace introduces on set 2-14-08  • The twins go out for a stroll (2/11/08) • The twins at 3 months (2/4/08) • The twins in January (1/21/08) • VIDEO: First video of Nancy Grace's twins  E-mail to a friend .\n",
            ">> Highlights: Pictures of Nancy Grace's twins .\n",
            "John David and Lucy Elizabeth were born November 4, 2007 .\n",
            "Come back to this site for regularly updated pictures!\n",
            "\n",
            ">> Article: (InStyle) -- After years in the bronze age, when sun-kissed cheeks and gloss reigned supreme, fall's return to glamour means that lipstick is making a major comeback. Lipstick outsold gloss by $76 million last year, and beauty companies are racing to launch new formulas that are more wearable than ever. So pucker up. We'll show you how to apply lipstick perfectly, along with the most flattering shades for day and night. For foolproof application, stick with sheer, subdued shades in the morning and save deep, bold colors (which require more time and precision) for night. Daytime equation . 1. Condition and protect with a balm that contains sunscreen, like Softlips Raspberry with Green Tea SPF 20. \"Dab some on immediately after getting out of the shower, when your lips are still a little moist,\" suggests Hollywood pro Kara Yoshimoto Bua. The smoother your lips, the more perfect your lipstick will look. 2. Choose a soft shade such as rose or nude that you can apply straight from the tube. A hydrating formula ensures a smooth coat of color. Try Neutrogena Moistureshine Soothing Lipsheers in Fresh Rose. 3. Blot, reapply and blot again to remove excess oils and create a stain, says Bua. \"The color looks more natural and lasts longer.\" Instead of tissues, use lint-free blotting papers, like Boscia Fresh Blotting Linens ($10). Nighttime equation . 1. Exfoliate before applying a bold hue like red or burgundy. Sally Hansen Gentle Peel for Rough Lips ($10; at drugstores) uses fruit enzymes to remove dry patches. 2. Create a base with a gel-based primer that fills in fine lines around the mouth and helps lipstick go on more smoothly. One to try: Olay Regenerist lip treatment ($19; at drugstores). 3. Define the borders of your mouth with a pencil to prevent color from bleeding, says Robin Fredriksz, who gave Barrymore her deep fuchsia lip. To avoid an unnaturally dark outline, use a shade that's lighter than your lipstick, like Revlon Colorstay lip liner in Plum ($8; at drugstores). 4. Brush on color for more control. Try: Shu Uemura Kolinsky Portable Extra lipbrush ($35) with Isadora Perfect Moisture lipstick in Bordeaux Red ($11). Makeup artists' favorites . Just like us, cosmetics pros use the same lipsticks again and again. From the just right daytime rose to the classic evening red, here are some of their all-time go-to picks for day and night. Carmindy's neutral picks for day are designed to \"enhance your natural lip color.\" For night she recommends dark berry or true red for all skin tones. Her clients: Heidi Klum and Jamie-Lynn Sigler. Day shades: Benefit Silky Finish in Candy Store, $16; Givenchy Rouge Interdit in Secret Pink, $26. Night colors: Nars in Scarlet Empress, $23; Revlon Super Lustrous in Love That Red, $8; at drugstores. AJ Crimson likes a subtle pink or sheer beige for all skin tones during the day. For night he recommends bright red for fair complexions and a deep purple for darker ones. His clients: Missy Elliot and Amerie. Day shades: Chanel Rouge Hydrabase in Pink Sugar, $25; Laura Mercier in Candy Pink, ($22). Night colors: Maybelline Moisture Extreme in Royal Red, $7; at drugstores; MAC in Cyber, ($14). Melissa Silver uses fuchsia on cool skin tones and peachy nude on warm ones for day. For night, she says, \"anyone can wear plum or sheer red.\" Her clients: Renée Zellweger and Cindy Crawford. Day shades: Clinique Colour Surge Butter Shine in Fresh Watermelon, $14; Lancôme Le Rouge Absolu in Nectariche, $25. Night colors: MAC in Spice It Up!, $14; Sonia Kashuk in Sheer Cherry Blossom, $8. E-mail to a friend . Get a FREE TRIAL issue of InStyle - CLICK HERE! Copyright © 2007 Time Inc. All rights reserved.\n",
            ">> Highlights: Gloss taking backseat to bold colors in lipsticks .\n",
            "Exfoliate lips before applying a bold hue .\n",
            "Melissa Silver: \"Anyone can wear plum or sheer red\" at night .\n",
            "AJ Crimson likes subtle pink or sheer beige for all skin tones for day .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing the data**"
      ],
      "metadata": {
        "id": "H4Nwni6HRMTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoTbb1UORNAB",
        "outputId": "930be088-6a54-46e0-ecce-6ba7d490a3bc"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/d78aea13fa7ecd06c29e3e46195d6341255065d5/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-small\",\n",
            "  \"architectures\": [\n",
            "    \"T5WithLMHeadModel\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading file spiece.model from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/d78aea13fa7ecd06c29e3e46195d6341255065d5/spiece.model\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/d78aea13fa7ecd06c29e3e46195d6341255065d5/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at None\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/d78aea13fa7ecd06c29e3e46195d6341255065d5/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-small\",\n",
            "  \"architectures\": [\n",
            "    \"T5WithLMHeadModel\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5_fast.py:166: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of tokenization using 't5-small'"
      ],
      "metadata": {
        "id": "7K_oEOtKRQsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"I loved reading the Hunger Games!\")\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EurZ3rHWRBJm",
        "outputId": "d14b4b1f-a4a0-4fd3-dfe0-00b9897372c4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [27, 1858, 1183, 8, 26049, 5880, 55, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(inputs['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmzxdOfoRBLy",
        "outputId": "092e65e5-cb93-4543-b021-af5650f989f8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁I', '▁loved', '▁reading', '▁the', '▁Hunger', '▁Games', '!', '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We apply truncation to both the article and their highlights to ensure we don’t pass excessively long inputs to our model.\n",
        "\n",
        "The tokenizer has a **as_target_tokenizer()** function that allows you to tokenize the labels in parallel to the inputs.\n",
        "\n",
        "This is typically done using a context manager inside a preprocessing function that first encodes the inputs, and then encodes the labels as a separate column."
      ],
      "metadata": {
        "id": "FEtUZq2zRTZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Values for max_input_length and max_target_length, which set the upper limits for how long our article and their highlights can be\n",
        "# Since the article is typically much larger than the highlights, the values are scaled accordingly\n",
        "\n",
        "max_input_length = 400\n",
        "max_target_length = 100\n",
        "\n",
        "def preprocess_function(examples):\n",
        "  # Reviews are first tokenized\n",
        "  model_inputs = tokenizer(examples['article'], truncation=True, max_length=max_input_length)\n",
        "  # tokenizer for the target (highlights)\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    labels = tokenizer(examples['highlights'], truncation=True, max_length=max_target_length)\n",
        "  # The inputs are first encoded, and then the labels ('highlights') are encoded as a separate column\n",
        "  model_inputs['labels'] = labels['input_ids']\n",
        "  return model_inputs\n",
        "\n"
      ],
      "metadata": {
        "id": "PVGlRF5ARWmv"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = datasets.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "ca6339245ef640ada8becf290a12b499",
            "353a40b8e41d4eeca6b62a5abebccd91",
            "aaf27f00c6f34500ae04d816f7118ccf",
            "01b740a6947c4e25bc06bb5ff78e633c",
            "3924f2cd6d294295b458bcd8f77d09c5",
            "c4aeaa076b5a4ea9be978e9fc50e0cdd",
            "1db586a4061a45d2a07af535c833e5ca",
            "43cf8426f7b04a43ba0f4297e61d3cac",
            "d1bb67f464cc49a1a0458708b2a30900",
            "5008879e3b534d9ba1beafafd1a70350",
            "02dcfe2f3dc849d0a5e1af845c952c75",
            "52bff9bfdae042baa520669886a8dcfe",
            "216f1a75561c4d889dbf26bc0c2cbc0b",
            "01fc60bf3af446f4b243fc9c88bb1e6d",
            "6ca1ecbcb5bb461b91b3a67c52e54aa3",
            "0464505ca94b493eaf00888b6dace609",
            "046112dbed294a8bbcf336232762b883",
            "a0f762d30dbd44c39c026a3277c59601",
            "bc91bd4d60084e77997b9b9a3e7f674a",
            "bd6fe33594fc447c89baa1f02a0a2a90",
            "5cc053524ebc4ec49acc7489e1b0f279",
            "a70f1f57c51a4d8d8cb61b3fca683055",
            "c904c900a6eb4dd98a1f83d031585662",
            "59554b0c0b3744fe93fdaf7246ee0f26",
            "94d999b92cad464fbe845448f89b9159",
            "0cf33b6475fd483398a60f9219c288a8",
            "94c483c7c3b74b12bf5acceac11b7489",
            "755073ce3796416194122ee88181a3ea",
            "8d87604dfbef4ccd9fbb93222395dbbf",
            "23bf8a423cdf4c688781ac971ed5f65a",
            "ff7c294de5ba4efc8f07ecea6d202f4c",
            "5cef939c4de3484682decf6383921d51",
            "b965d141b31d4d629a9c576eb3ffac86"
          ]
        },
        "id": "yoM7mhvSRYxu",
        "outputId": "fa486633-e7f8-49d8-d1d7-5c0bcd6e34ee"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca6339245ef640ada8becf290a12b499"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3547: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  \"`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your \"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52bff9bfdae042baa520669886a8dcfe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c904c900a6eb4dd98a1f83d031585662"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use batched=True in our Dataset.map() function above. This encodes the examples in batches of 1,000 (the default) and allows to make use of the multithreading capabilities of the fast tokenizers in Transformers."
      ],
      "metadata": {
        "id": "Z-AfJzehRbv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating a Baseline**"
      ],
      "metadata": {
        "id": "-aQ_RfYaRbs2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A common baseline for text summarization is to simply take the first three sentences of an article, often called the lead-3 baseline. We could use full stops to track the sentence boundaries, but this will fail on acronyms like “U.S.”\n",
        "\n",
        "Se we'll use the nltk library"
      ],
      "metadata": {
        "id": "_3GCvAzBRgBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVt-L7-XRiKF",
        "outputId": "606f26ab-3ec4-4990-ba28-659d296bb093"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the Punctuation rules:"
      ],
      "metadata": {
        "id": "m5rI_gotRiNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk \n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLJuAS_GRiQe",
        "outputId": "36cb5fc9-c42e-4b9d-9f58-2544d6412dd0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# s = '''Good muffins cost $3.88\\nin New York.  Please buy me two of them.\\n\\nThanks.'''\n",
        "# sent_tokenize(s)\n",
        "# ['Good muffins cost $3.88\\nin New York.', 'Please buy me\\ntwo of them.', 'Thanks.']\n",
        "\n",
        "# join method\n",
        "# myTuple = (\"John\", \"Peter\", \"Vicky\")\n",
        "# x = \"#\".join(myTuple); print(x)\n",
        "# OP: John#Peter#Vicky\n",
        "\n",
        "def three_sentence_summary(text):   # function to extract 1st 3 sentences in the text\n",
        "  return '\\n'.join(sent_tokenize(text)[:3])   # first 3 sentence only\n",
        "\n",
        "print(three_sentence_summary(datasets['train'][3]['article']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQrD65y9RiTN",
        "outputId": "40ebc5e1-9467-4c66-b3c9-9d88bcf36d5c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WASHINGTON (CNN) -- Doctors removed five small polyps from President Bush's colon on Saturday, and \"none appeared worrisome,\" a White House spokesman said.\n",
            "The polyps were removed and sent to the National Naval Medical Center in Bethesda, Maryland, for routine microscopic examination, spokesman Scott Stanzel said.\n",
            "Results are expected in two to three days.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define a function which extracts these 'summaries' (1st 3 sentences) and compute rouge scores for them with 'summaries' as predictions and the 'highlights' as references in .compute() method"
      ],
      "metadata": {
        "id": "_71wvVqBRulm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_baseline(dataset, metric):\n",
        "  summaries = [three_sentence_summary(text) for text in dataset['article']]\n",
        "  return metric.compute(predictions=summaries, references=dataset['highlights'])"
      ],
      "metadata": {
        "id": "JMVZ1aoVRu8x"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use this function to compute rouge scores over the validation set."
      ],
      "metadata": {
        "id": "U36R8vM_RiU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC9nfYzER8De",
        "outputId": "0831ad42-ab08-465c-9a72-aa5588bc9971"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.21.6)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (7.1.2)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=a754cc2bb8c8545350fefd4e63ee283c1f04cf8d1d7583b153ddc53df09ad2bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ac/6b/38096e3c5bf1dc87911e3585875e21a3ac610348e740409c76\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuyd1ILLR8Fi",
        "outputId": "2349fdb6-fd9a-42c6-b277-716c33122b58"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.6.1)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.10.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.13.1)\n",
            "Requirement already satisfied: protobuf<=3.20.2 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n",
            "Collecting sentencepiece!=0.1.92,>=0.1.91\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 11.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece, evaluate\n",
            "Successfully installed evaluate-0.3.0 sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "rouge_score = evaluate.load('rouge')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a555c7e8efe543749a71e84b41ebad1c",
            "8f2a114990584102b9bb31d8be3e9d1b",
            "80438cbc00974dedb5db66e0972a44c7",
            "499031bd997341cda9f83d8a72a46276",
            "390f720f77334615bb2656ac079a1f35",
            "59e6a91c81dd4978bf4a414ac973600e",
            "cc8e41446f1d48ef89d9d639b2d13367",
            "2967ea52f2a7489d8dd2007970ab6bf7",
            "b0617419afe74eba908b67d25dd77ac5",
            "bfdaee5d094748248b540412cca909cb",
            "ef69b05a6b984e1bac3db072838697cf"
          ]
        },
        "id": "rBTTzYNkR8KW",
        "outputId": "c62afbb9-ec91-4082-d03c-726891f4afc7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a555c7e8efe543749a71e84b41ebad1c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# x = dict(name = \"John\", age = 36, country = \"Norway\")\n",
        "# OP: {'name': 'John', 'age': 36, 'country': 'Norway'}\n",
        "\n",
        "# round() -> returns a floating point number that is a rounded version of the specified number, with the specified number of decimals.\n",
        "# round(5.76543, 2) -> 5.77\n",
        "\n",
        "score = evaluate_baseline(datasets['validation'], rouge_score)\n",
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "rouge_dict = dict((rn, round(score[rn]*100, 2)) for rn in rouge_names)\n",
        "\n",
        "rouge_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_bCVOsySBMC",
        "outputId": "ca19e862-4f6a-4e7e-f390-968373b35222"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 27.78, 'rouge2': 10.82, 'rougeL': 18.91, 'rougeLsum': 24.94}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the rouge2 score is significantly lower than the rest; this likely reflects the fact that highlights are typically concise and so the lead-3 baseline is too verbose (using or expressed in more words than are needed)."
      ],
      "metadata": {
        "id": "b0TkqEluSD63"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fine-tuning T5 with the Trainer API**"
      ],
      "metadata": {
        "id": "HzNS-faeSFam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "# Seq2SeqLM: sequence-to-sequence language modeling head\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)  # model_checkpoint = \"t5-small\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEiaklLPSIKe",
        "outputId": "279dcb68-00fd-4ace-aaa7-98a4fe5c6d26"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/d78aea13fa7ecd06c29e3e46195d6341255065d5/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-small\",\n",
            "  \"architectures\": [\n",
            "    \"T5WithLMHeadModel\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/d78aea13fa7ecd06c29e3e46195d6341255065d5/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We’ll need to generate summaries in order to compute ROUGE scores during training.\n",
        "\n",
        "Hugging Face transformers provides Seq2SeqTrainingArguments and Seq2SeqTrainer classes that can do this automatically."
      ],
      "metadata": {
        "id": "5WQb7X_FSK7S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For summarization evaluation is a bit more involved than simply calling rouge_score.compute() on the model’s predictions, since we need to decode the outputs and labels into text before we can compute the ROUGE scores."
      ],
      "metadata": {
        "id": "kg0hVj-7SJmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metric(eval_pred):\n",
        "  predictions, labels = eval_pred\n",
        "  # Decode generated summaries into text (summaries generated from the review_body)\n",
        "  # batch_decode -> Returns List[str]; The list of decoded sentences; Convert a list of lists of token ids into a list of strings by calling decode.\n",
        "  decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True) # skip_special_tokens - Whether or not to remove special tokens in the decoding.\n",
        "  # Replace -100 in the labels as we can't decode them\n",
        "  labels = np.where(labels!=-100, labels, tokenizer.pad_token_id)\n",
        "  # Decode reference summaries into text ('review_title')\n",
        "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "  # ROUGE expects a newline after each sentence\n",
        "  # strip() method removes characters from both left and right based on the argument\n",
        "  decoded_preds = ['\\n'.join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "  decoded_labels = ['\\n'.join(sent_tokenize(pred.strip())) for pred in decoded_labels]\n",
        "  # Computing ROUGE score\n",
        "  # Stemming is used to remove plurals and word suffixes such as (ing, ion, ment)\n",
        "  result = rouge_score.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "  result = {key: value*100 for key, value in result.items()}\n",
        "  return {k: round(v,4) for k, v in result.items()}"
      ],
      "metadata": {
        "id": "5v66mx1oSIN1"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to define a data collator for our sequence-to-sequence task. Since T5 is an encoder-decoder Transformer model, one subtlety with preparing our batches is that during decoding we need to shift the labels to the right by one. This is required to ensure that the decoder only sees the previous ground truth labels and not the current or future ones, which would be easy for the model to memorize.\n",
        "\n",
        "Hugging Face Transformers provides a **DataCollatorForSeq2Seq collator** that will dynamically pad the inputs and the labels for us. "
      ],
      "metadata": {
        "id": "ZkoeNIOCSITG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "RdPhRu19SIVs"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to remove the columns with strings because the collator won’t know how to pad these elements"
      ],
      "metadata": {
        "id": "fbe_uBE7SaKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets['train'].column_names, len(datasets['train'].column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUH4ooyJSYIW",
        "outputId": "f66a2dfb-21ca-4cf4-a43d-fd340fa69bbf"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['article', 'highlights', 'id'], 3)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset['train'].column_names, len(tokenized_dataset['train'].column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2wDOFqjSYiD",
        "outputId": "f47029b2-c696-427d-c874-e8dfc7af3058"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'], 6)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenized_dataset.remove_columns(datasets['train'].column_names)"
      ],
      "metadata": {
        "id": "F_QQ_l5iSYko"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset['train'].column_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be7ZZ73fSYm9",
        "outputId": "d134a768-c3bd-4899-c51b-47b51f671da3"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['input_ids', 'attention_mask', 'labels']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = [tokenized_dataset['train'][i] for i in range(2)]\n",
        "data_collator(features)\n",
        "\n",
        "# Notice we have info ['input_ids', 'attention_mask', 'labels'] for 2 examples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KWxiO9FSYpN",
        "outputId": "abcb7921-76bd-40be-cbca-4f39468f2710"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  301, 24796,  4170,     6,  2789,    41, 18844,    61,  1636,  8929,\n",
              "         16023,  2213,  4173,  6324, 12591,    15, 11391,   592,    12,     3,\n",
              "             9,  2196,  3996,  1755,   770,  8785,   591, 11039,   770,    61,\n",
              "         13462,    38,     3,    88,  5050,   507,    30,  2089,     6,    68,\n",
              "             3,    88, 10419,     7,     8,   540,   751,    31,    17,  4061,\n",
              "             3,     9, 10783,    30,   376,     5,  4173,  6324, 12591,    15,\n",
              "            38,  8929, 16023,    16,    96, 15537,   651, 16023,    11,     8,\n",
              "          5197,    13,     8, 12308,   121,   304,     8, 19142,    13, 29517,\n",
              "          6710,   343,     7,   300,     8,   296,     6,     8,  1021,  7556,\n",
              "           845,     3,    88,    65,   150,  1390,    12,  9030,    17,   449,\n",
              "           112,  1723,   550,    30,  1006,  2948,     6,  3281,    11, 17086,\n",
              "          2251,     5,    96,   196,   278,    31,    17,   515,    12,    36,\n",
              "            80,    13,   273,   151,   113,     6,    38,  1116,    38,    79,\n",
              "           919, 14985,  8247,   805,  1452,     3,     9,  3805,  2100,   443,\n",
              "          1232,    42,   424,  1126,   976,     3,    88,  1219,    46,  3746,\n",
              "          2772,    49,  2283,    48,   847,     5,    96,   196,   278,    31,\n",
              "            17,   317,    27,    31,   195,    36,  1989, 28887,     5,    96,\n",
              "           634,   378,    27,   114,  2611,    33,   378,    24,   583,    81,\n",
              "           335,  7051,  1636,  1335,    11,  3190,     7,    11,  5677,     7,\n",
              "           535,   486, 14985,  6324, 12591,    15,    56,    36,     3,   179,\n",
              "            12, 24068,    16,     3,     9,  2653,     6,   805,     3,     9,\n",
              "          3281,    16,     3,     9, 11943,    42,   217,     8, 12082,   814,\n",
              "            96,  4489,     7,  1625,    10,  2733,  2466,   976,  1083,  1296,\n",
              "          1747,   666,   112,   381,    80,  1974,    30,     8,  1270,  1367,\n",
              "           828,  5059,     5,  9487,    13,   149,     3,    88,    31,   195,\n",
              "          3946,   112, 15754,  3591,    33,   365,  6215,     7,     5,   978,\n",
              "          3102,    11,   452,   343,   141,   150,  1670,    30,   112,  1390,\n",
              "             5,    96,   196,    31,   195,  1728,    43,   128,  1843,    13,\n",
              "          1088,   976,     3,    88,   243,    16,    46,  2772,     5,    96,\n",
              "         12599,  5839,    13,    25,    56,    36,  1183,    81,    34,   535,\n",
              "          6324, 12591,    15,    31,     7,  8783,    45,     8,   166,   874,\n",
              "         16023,  4852,    43,   118,  1213,    16,     3,     9,  2019,  3069,\n",
              "            84,     3,    88,    65,    59,   118,     3,   179,    12,  1586,\n",
              "             5,     3,  4868,   112,  1710, 10393,    11, 20816,     6,     8,\n",
              "          7556,   845,     3,    88,    19,  2627,   112,  1922,     3, 16804,\n",
              "            30,     8,  1591,     5,    96, 24337,    33,   373,   479,    12,\n",
              "           497,     3,    31,  2168,    26,  2213,  1550,   326,     8,  6579,\n",
              "             7,     6,    31,   121,     3,    88,  1219, 19644,   336,   847,\n",
              "             5,    96, 11836,    27,   653,   182,   614,    59,    12,   281,\n",
              "            24,   194,   250,    34,   133,    36,   396,   514,    21,     1],\n",
              "        [11953,    31,     7,  2232,    10,    86,    69, 17088,     8, 27814,\n",
              "             7,   939,     6, 19602, 25688,     7,   698,    70,  2704,    16,\n",
              "          6013,  1506,    11,  8341,     8,  1937,  1187,     8,   984,     5,\n",
              "           947,     6,   264,   109, 14677,   411,    31,   279,  3483,  1217,\n",
              "          1105,  1096,     3,     9, 11796,   213,   186,    13,     8,    16,\n",
              "         11171,    33, 19367,     3,  1092,     5,   389,    16,  5058,   629,\n",
              "            26,    30,     8,    96,  1161,  7483,  1501,   976,   213,   186,\n",
              "         19367,     3,  1092,    16, 11171,    33,   629,    26,    16,  8327,\n",
              "           274,  3689,     5,  8161,  4815,   196,     6,  2599,    41,   254,\n",
              "         17235,    61,  1636,    37, 24651,  1501,    13,     8,  8327,    18,\n",
              "           308,     9,   221,  7140, 12042,    20,  9174,  3064,    19,     3,\n",
              "            26, 17344,     8,    96,  1161,  7483,  1501,   535,   947,     6,\n",
              "            16, 11171,    28,     8,   167,  5274,  2550, 21154,    33,     3,\n",
              "         14736,    15,  4094,   552,    79,    31,    60,  1065,    12,  2385,\n",
              "            16,  1614,     5,  1377,   557,     6,    79,   522,  2672,  3991,\n",
              "            42,  3991,    13, 12710,    53,    46,  5502,  1636,  7993,     7,\n",
              "            24, 12330,  9316,   312,    99,   348,   845,    33,  1086,    96,\n",
              "             9, 12186,   179,  3110,   106,   725,   535,   216,   845,     8,\n",
              "         10319,     7,   557,   741,    45, 25704,     7,    28,  2095,     5,\n",
              "         17054,   120,     3,  1092,   151,   557,   751,    31,    17,   103,\n",
              "           125,    79,    31,    60,  1219,   116,  2095,  3658,    30,     8,\n",
              "          3112,  1636, 25704,  1330,    12,     3, 31488,    70,  7095,    11,\n",
              "            79,   582,    72,  3856,  5983,    26,     6,    20,  7650,  6318,\n",
              "             6,    11,   705,   952,    12,  1130,  7943,     6,  1315,    12,\n",
              "           312,    99,   348,     5,   264,     6,    79,   414,    95,    30,\n",
              "             8, 24651,  1501, 20215, 19367, 30371,     6,    68,    59,   652,\n",
              "           136,   490,   199,   250,    79,    31,    60,    16, 11796,     5,\n",
              "           101,     3, 28059,     8, 11796,    28,   312,    99,   348,     5,\n",
              "           216,    19,   168,   801,    16,  8327,    38,    46, 11223,    21,\n",
              "          4831,    11,     8, 19367,     3,  1092,     5,  1441,   713,    62,\n",
              "           130,    59,  1776, 13001,    28,   539,  6026,    57,     8,  4879,\n",
              "             7,     6,    62,   130,   787,  6059,    12,  4279,   671,  8873,\n",
              "            15,    11,  1552,     8,  1501,     5,  1263,  1096,     8,     3,\n",
              "            31,  1161,  7483,  1501,    31,  1168,     3,     5,   486,   166,\n",
              "             6,    34,    31,     7,   614,    12,  2082,   213,     8,   151,\n",
              "            33,     5,    37, 22040,    33,  5119,     3,     7,   109,    15,\n",
              "           162,   924,     3,  9598,     7,     5, 11648,  3753,  8034,    21,\n",
              "          6026,    11,  1922,    16,     3,     9,  2437, 13996,  9182,  2182,\n",
              "          1636,    24,    31,     7,   773,    13,   125,    79,   320,   114,\n",
              "             5,   328,    31,    60,   876,    12,   453,     8, 19367,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[ 8929, 16023,  2213,  4173,  6324, 12591,    15,  2347,  3996,  1755,\n",
              "           329, 13462,    38,     3,    88,  5050,   507,  2089,     3,     5,\n",
              "          5209,  7556,   845,     3,    88,    65,   150,  1390,    12,  9030,\n",
              "            17,   449,   112,  1723,   550,     3,     5,  6324, 12591,    15,\n",
              "            31,     7,  8783,    45,   166,   874, 16023,  4852,    43,   118,\n",
              "          1213,    16,  2019,  3069,     3,     5,     1,  -100,  -100,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
              "        [17054,   120,     3,  1092,    16, 11171,    16,  8327,    33,   629,\n",
              "            26,    30,     8,    96,  1161,  7483,  1501,   121, 12330,  9316,\n",
              "           312,    99,   348,   845,   167,    33,   132,    38,     3,     9,\n",
              "           741,    13,    96,     9, 12186,   179,  3110,   106,   725,   121,\n",
              "           818, 19602,  8108,  3064,     6,  1868, 14314,     7,    10,    96,\n",
              "           196,   183,     8,   520,    13,     8,  2753,   121,   312,    99,\n",
              "           348,   845,     8,   358,    19,    73,  4998,    11,     3,    88,\n",
              "            31,     7,  6237,    21,   483,     3,     5,     1]]), 'decoder_input_ids': tensor([[    0,  8929, 16023,  2213,  4173,  6324, 12591,    15,  2347,  3996,\n",
              "          1755,   329, 13462,    38,     3,    88,  5050,   507,  2089,     3,\n",
              "             5,  5209,  7556,   845,     3,    88,    65,   150,  1390,    12,\n",
              "          9030,    17,   449,   112,  1723,   550,     3,     5,  6324, 12591,\n",
              "            15,    31,     7,  8783,    45,   166,   874, 16023,  4852,    43,\n",
              "           118,  1213,    16,  2019,  3069,     3,     5,     1,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0, 17054,   120,     3,  1092,    16, 11171,    16,  8327,    33,\n",
              "           629,    26,    30,     8,    96,  1161,  7483,  1501,   121, 12330,\n",
              "          9316,   312,    99,   348,   845,   167,    33,   132,    38,     3,\n",
              "             9,   741,    13,    96,     9, 12186,   179,  3110,   106,   725,\n",
              "           121,   818, 19602,  8108,  3064,     6,  1868, 14314,     7,    10,\n",
              "            96,   196,   183,     8,   520,    13,     8,  2753,   121,   312,\n",
              "            99,   348,   845,     8,   358,    19,    73,  4998,    11,     3,\n",
              "            88,    31,     7,  6237,    21,   483,     3,     5]])}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first example is longer than the second one, so the input_ids and attention_mask of the second example have been padded on the right with a [PAD] token (whose ID is 0). Similarly, we can see that the labels have been padded with -100s, to make sure the padding tokens are ignored by the loss function. And finally, we can see a new decoder_input_ids which has shifted the labels to the right by inserting a [PAD] token in the first entry."
      ],
      "metadata": {
        "id": "y5t-tI8jSoRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training 1**\n",
        "\n",
        "*Number of epochs = 3*\n",
        "\n",
        "*Learning rate = 5.6 e-5*"
      ],
      "metadata": {
        "id": "yI72ptskb81Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "# parameters of Seq2SeqTrainingArguments\n",
        "batch_size = 8\n",
        "num_training_epochs = 3\n",
        "logging_steps = len(tokenized_dataset[\"train\"])//8\n",
        "\n",
        "args = Seq2SeqTrainingArguments(evaluation_strategy='epoch',\n",
        "                                learning_rate=5.6e-5,\n",
        "                                per_device_train_batch_size=batch_size,\n",
        "                                per_device_eval_batch_size=batch_size,\n",
        "                                weight_decay=0.01,\n",
        "                                save_total_limit=3,\n",
        "                                num_train_epochs=num_training_epochs,\n",
        "                                predict_with_generate=True,\n",
        "                                logging_steps=logging_steps,\n",
        "                                output_dir=\"t5-finetuned-cnn-dailymail-english\")\n",
        "                               # push_to_hub=True\n",
        "\n",
        "# predict_with_generate argument has been set to True to indicate that we should generate summaries\n",
        "# during evaluation so that we can compute ROUGE scores for each epoch\n",
        "# The decoder performs inference by predicting tokens one by one, and this is implemented by the model’s \n",
        "# generate() method. Setting predict_with_generate=True tells the Seq2SeqTrainer to use that method for evaluation.\n",
        "# save_total_limit = 3 -> because even the “small” version of T5 uses around a GB of hard drive space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0ne1cYDSLcB",
        "outputId": "93d876af-6a44-4608-f220-20b811b4ccbc"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset['train']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntwdvph6SYrn",
        "outputId": "60fe0697-3512-4b19-c4d0-fe71c42a49b6"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 300\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "# args = Seq2SeqTrainingArguments()\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained('t5-small')\n",
        "# tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
        "trainer = Seq2SeqTrainer(model, args, train_dataset=tokenized_dataset[\"train\"], eval_dataset=tokenized_dataset[\"validation\"], \n",
        "                         data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metric)"
      ],
      "metadata": {
        "id": "eKXH0N8_Sr00"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "81FYLLv7V-yt",
        "outputId": "4b2251ef-1541-4a4c-b017-0d4e11fb4063"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 300\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 114\n",
            "  Number of trainable parameters = 60506624\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [114/114 35:00, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.420800</td>\n",
              "      <td>2.205768</td>\n",
              "      <td>23.348200</td>\n",
              "      <td>8.602800</td>\n",
              "      <td>19.274600</td>\n",
              "      <td>21.339000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.367000</td>\n",
              "      <td>2.192145</td>\n",
              "      <td>23.545300</td>\n",
              "      <td>8.825200</td>\n",
              "      <td>19.335600</td>\n",
              "      <td>21.509800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.280400</td>\n",
              "      <td>2.193337</td>\n",
              "      <td>23.916500</td>\n",
              "      <td>8.846900</td>\n",
              "      <td>19.714600</td>\n",
              "      <td>21.983600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 150\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 150\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 150\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=114, training_loss=2.3556214006323564, metrics={'train_runtime': 2114.868, 'train_samples_per_second': 0.426, 'train_steps_per_second': 0.054, 'total_flos': 95162204160000.0, 'train_loss': 2.3556214006323564, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the training is complete, we can see the final ROUGE scores by running trainer.evaluate(): "
      ],
      "metadata": {
        "id": "Om6fNZo9S0Su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "849RdeCBSvz5",
        "outputId": "ab2e12ed-7008-4dce-f8c5-1ee75eda619f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 150\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [19/19 02:38]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 2.1933369636535645,\n",
              " 'eval_rouge1': 23.9165,\n",
              " 'eval_rouge2': 8.8469,\n",
              " 'eval_rougeL': 19.7146,\n",
              " 'eval_rougeLsum': 21.9836,\n",
              " 'eval_runtime': 168.2002,\n",
              " 'eval_samples_per_second': 0.892,\n",
              " 'eval_steps_per_second': 0.113,\n",
              " 'epoch': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training 2**\n",
        "\n",
        "*Number of epochs = 2*\n",
        "\n",
        "*Learning rate = 5.6 e - 4* (Increasing the learning rate)"
      ],
      "metadata": {
        "id": "kU3ozXiAfnSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "# parameters of Seq2SeqTrainingArguments\n",
        "batch_size = 8\n",
        "num_training_epochs = 2\n",
        "logging_steps = len(tokenized_dataset[\"train\"])//8\n",
        "\n",
        "args_2 = Seq2SeqTrainingArguments(evaluation_strategy='epoch',\n",
        "                                learning_rate=5.6e-4,\n",
        "                                per_device_train_batch_size=batch_size,\n",
        "                                per_device_eval_batch_size=batch_size,\n",
        "                                weight_decay=0.01,\n",
        "                                save_total_limit=3,\n",
        "                                num_train_epochs=num_training_epochs,\n",
        "                                predict_with_generate=True,\n",
        "                                logging_steps=logging_steps,\n",
        "                                output_dir=\"t5-finetuned-cnn-dailymail-english\")\n",
        "                               # push_to_hub=True\n",
        "\n",
        "# predict_with_generate argument has been set to True to indicate that we should generate summaries\n",
        "# during evaluation so that we can compute ROUGE scores for each epoch\n",
        "# The decoder performs inference by predicting tokens one by one, and this is implemented by the model’s \n",
        "# generate() method. Setting predict_with_generate=True tells the Seq2SeqTrainer to use that method for evaluation.\n",
        "# save_total_limit = 3 -> because even the “small” version of T5 uses around a GB of hard drive space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mBbQM9jfoi9",
        "outputId": "01ca3018-ce6e-41db-b44a-b5ba3837ffac"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "# args = Seq2SeqTrainingArguments()\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained('t5-small')\n",
        "# tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
        "trainer_2 = Seq2SeqTrainer(model, args_2, train_dataset=tokenized_dataset[\"train\"], eval_dataset=tokenized_dataset[\"validation\"], \n",
        "                         data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metric)"
      ],
      "metadata": {
        "id": "sfVCox1cfok8"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_2.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "yqGMYqJGfood",
        "outputId": "c5069386-8e8a-4439-bc95-3cfb98e7dcaa"
      },
      "execution_count": 75,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 300\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 76\n",
            "  Number of trainable parameters = 60506624\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/76 04:20 < 13:31, 0.07 it/s, Epoch 0.50/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [76/76 24:01, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.197300</td>\n",
              "      <td>2.206004</td>\n",
              "      <td>24.660300</td>\n",
              "      <td>9.245600</td>\n",
              "      <td>20.091100</td>\n",
              "      <td>22.549600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.001100</td>\n",
              "      <td>2.243958</td>\n",
              "      <td>22.751900</td>\n",
              "      <td>7.598800</td>\n",
              "      <td>18.534800</td>\n",
              "      <td>20.763000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 150\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 150\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=76, training_loss=2.0879521840497066, metrics={'train_runtime': 1456.2115, 'train_samples_per_second': 0.412, 'train_steps_per_second': 0.052, 'total_flos': 63441469440000.0, 'train_loss': 2.0879521840497066, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_2.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "aebbvdY9f2t8",
        "outputId": "1495e7d2-558f-4b40-8ae4-78f68e61acd5"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 150\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [19/19 03:49]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 2.24395751953125,\n",
              " 'eval_rouge1': 22.7519,\n",
              " 'eval_rouge2': 7.5988,\n",
              " 'eval_rougeL': 18.5348,\n",
              " 'eval_rougeLsum': 20.763,\n",
              " 'eval_runtime': 251.0672,\n",
              " 'eval_samples_per_second': 0.597,\n",
              " 'eval_steps_per_second': 0.076,\n",
              " 'epoch': 2.0}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training 3**\n",
        "\n",
        "Since the score decreased with increasing epochs, meaning the model overfitted; so reducing learning rate:\n",
        "\n",
        "*Number of epochs = 2*\n",
        "\n",
        "*Learning rate = 9.0 e - 5* (Reducing the learning rate)"
      ],
      "metadata": {
        "id": "yGyQqpJLmiUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "# parameters of Seq2SeqTrainingArguments\n",
        "batch_size = 8\n",
        "num_training_epochs = 2\n",
        "logging_steps = len(tokenized_dataset[\"train\"])//8\n",
        "\n",
        "args_3 = Seq2SeqTrainingArguments(evaluation_strategy='epoch',\n",
        "                                learning_rate=9e-5,\n",
        "                                per_device_train_batch_size=batch_size,\n",
        "                                per_device_eval_batch_size=batch_size,\n",
        "                                weight_decay=0.01,\n",
        "                                save_total_limit=3,\n",
        "                                num_train_epochs=num_training_epochs,\n",
        "                                predict_with_generate=True,\n",
        "                                logging_steps=logging_steps,\n",
        "                                output_dir=\"t5-finetuned-cnn-dailymail-english\")\n",
        "                               # push_to_hub=True\n",
        "\n",
        "# predict_with_generate argument has been set to True to indicate that we should generate summaries\n",
        "# during evaluation so that we can compute ROUGE scores for each epoch\n",
        "# The decoder performs inference by predicting tokens one by one, and this is implemented by the model’s \n",
        "# generate() method. Setting predict_with_generate=True tells the Seq2SeqTrainer to use that method for evaluation.\n",
        "# save_total_limit = 3 -> because even the “small” version of T5 uses around a GB of hard drive space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUef0RF3muVc",
        "outputId": "df6433c2-dd93-44dc-d510-3d823c1a79a0"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "# args = Seq2SeqTrainingArguments()\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained('t5-small')\n",
        "# tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
        "trainer_3 = Seq2SeqTrainer(model, args_3, train_dataset=tokenized_dataset[\"train\"], eval_dataset=tokenized_dataset[\"validation\"], \n",
        "                         data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metric)"
      ],
      "metadata": {
        "id": "HLI9M6eQmxGM"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_3.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "owyVQ5yWmxJo",
        "outputId": "1e689b2a-9833-4271-f3a2-1b8c593ed31b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 300\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 76\n",
            "  Number of trainable parameters = 60506624\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='77' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [76/76 21:14, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.410100</td>\n",
              "      <td>2.332085</td>\n",
              "      <td>22.662200</td>\n",
              "      <td>7.913400</td>\n",
              "      <td>18.351400</td>\n",
              "      <td>20.785600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/19 02:22 < 00:28, 0.11 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 150\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 150\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [76/76 24:13, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.410100</td>\n",
              "      <td>2.332085</td>\n",
              "      <td>22.662200</td>\n",
              "      <td>7.913400</td>\n",
              "      <td>18.351400</td>\n",
              "      <td>20.785600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.667800</td>\n",
              "      <td>2.337316</td>\n",
              "      <td>22.217800</td>\n",
              "      <td>7.669600</td>\n",
              "      <td>18.023100</td>\n",
              "      <td>20.442000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=76, training_loss=1.5414059350365086, metrics={'train_runtime': 1468.7524, 'train_samples_per_second': 0.409, 'train_steps_per_second': 0.052, 'total_flos': 63441469440000.0, 'train_loss': 1.5414059350365086, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_3.evaluate()"
      ],
      "metadata": {
        "id": "r26vUit1m2jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training 4**\n",
        "\n",
        "*Number of epochs = 8* (Increasing number of epochs)\n",
        "\n",
        "*Learning rate = 5.6 e-5*"
      ],
      "metadata": {
        "id": "6VemKoudt40Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "# parameters of Seq2SeqTrainingArguments\n",
        "batch_size = 8\n",
        "num_training_epochs = 8\n",
        "logging_steps = len(tokenized_dataset[\"train\"])//8\n",
        "\n",
        "args_4 = Seq2SeqTrainingArguments(evaluation_strategy='epoch',\n",
        "                                learning_rate=5.6e-5,\n",
        "                                per_device_train_batch_size=batch_size,\n",
        "                                per_device_eval_batch_size=batch_size,\n",
        "                                weight_decay=0.01,\n",
        "                                save_total_limit=3,\n",
        "                                num_train_epochs=num_training_epochs,\n",
        "                                predict_with_generate=True,\n",
        "                                logging_steps=logging_steps,\n",
        "                                output_dir=\"t5-finetuned-cnn-dailymail-english\")\n",
        "                               # push_to_hub=True\n",
        "\n",
        "# predict_with_generate argument has been set to True to indicate that we should generate summaries\n",
        "# during evaluation so that we can compute ROUGE scores for each epoch\n",
        "# The decoder performs inference by predicting tokens one by one, and this is implemented by the model’s \n",
        "# generate() method. Setting predict_with_generate=True tells the Seq2SeqTrainer to use that method for evaluation.\n",
        "# save_total_limit = 3 -> because even the “small” version of T5 uses around a GB of hard drive space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns4OcQZLuCau",
        "outputId": "68c70b70-bca0-46b6-be85-d2a9bf8108df"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "# args = Seq2SeqTrainingArguments()\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained('t5-small')\n",
        "# tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
        "trainer_4 = Seq2SeqTrainer(model, args_4, train_dataset=tokenized_dataset[\"train\"], eval_dataset=tokenized_dataset[\"validation\"], \n",
        "                         data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metric)"
      ],
      "metadata": {
        "id": "esGhBH8buDls"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_4.train()"
      ],
      "metadata": {
        "id": "-npmont5unmY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}